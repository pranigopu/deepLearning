# Module coursework for deep learning for audio and music

For more information about this coursework, read: [INFO.md](https://github.com/pranigopu/deepLearning--for--audio-music/blob/4e33739eea581d1f131ba4cc03d926456157d027/coursework/INFO.md)

## Proposed project

The 2 DL inferences:

- Major/minor classifier (using CNN)
- Time signature classifier (using RNN)

Inference combinations (of the above 2 DL inferences):

- Single CNN model
- Composite model
- Sequential CNN model (output of time signature as input to major/minor classifier)

_Compare the outcomes of the above 3._

## Resources

- Royalty-free audio loops: https://www.looperman.com/
- Royalty-free audio files: https://www.jamendo.com/
- Potential datasets:
    - Musical key & tempo datasets: http://www.cp.jku.at/datasets/giantsteps/
        - Key: https://github.com/GiantSteps/giantsteps-key-dataset
        - tempo: https://github.com/GiantSteps/giantsteps-tempo-dataset
    - Musical key datasets: https://paperswithcode.com/paper/pop909-a-pop-song-dataset-for-music
        - Key: https://github.com/music-x-lab/POP909-Dataset/tree/master
    - Musical key & time signature datasets: http://millionsongdataset.com/
