# Module coursework for deep learning for audio and music

For more information about this coursework, read: [INFO.md](https://github.com/pranigopu/deepLearning--for--audio-music/blob/4e33739eea581d1f131ba4cc03d926456157d027/coursework/INFO.md)

## Proposed project

The 2 DL inferences:

- Major/minor classifier (using CNN)
- Time signature classifier (using RNN)

Inference combinations (of the above 2 DL inferences):

- Single CNN model
- Composite model
- Sequential CNN model (output of time signature as input to major/minor classifier)

_Compare the outcomes of the above 3._

## Resources

- Royalty-free audio loops: https://www.looperman.com/
- Royalty-free audio files: https://www.jamendo.com/
- Potential datasets:
- Datasets:
    - http://www.cp.jku.at/datasets/giantsteps/
        - https://github.com/GiantSteps/giantsteps-key-dataset (KEY)
        - https://github.com/GiantSteps/giantsteps-tempo-dataset (TEMPO)
    - https://paperswithcode.com/paper/pop909-a-pop-song-dataset-for-music
        - https://github.com/music-x-lab/POP909-Dataset/tree/master (KEY)
